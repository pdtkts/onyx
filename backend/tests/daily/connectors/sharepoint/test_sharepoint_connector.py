import os
import time
from dataclasses import dataclass
from datetime import datetime
from datetime import timezone
from unittest.mock import MagicMock
from unittest.mock import patch

import pytest

from onyx.configs.constants import DocumentSource
from onyx.connectors.models import Document
from onyx.connectors.models import HierarchyNode
from onyx.connectors.models import ImageSection
from onyx.connectors.sharepoint.connector import SharepointConnector
from onyx.db.enums import HierarchyNodeType
from tests.daily.connectors.utils import load_all_from_connector

# NOTE: Sharepoint site for tests is "sharepoint-tests"


@dataclass
class ExpectedDocument:
    semantic_identifier: str
    content: str
    folder_path: str | None = None
    library: str = "Shared Documents"  # Default to main library
    expected_link_substrings: list[str] | None = None


EXPECTED_DOCUMENTS = [
    ExpectedDocument(
        semantic_identifier="test1.docx",
        content="test1",
        folder_path="test",
        expected_link_substrings=["_layouts/15/Doc.aspx", "file=test1.docx"],
    ),
    ExpectedDocument(
        semantic_identifier="test2.docx",
        content="test2",
        folder_path="test/nested with spaces",
        expected_link_substrings=["_layouts/15/Doc.aspx", "file=test2.docx"],
    ),
    ExpectedDocument(
        semantic_identifier="should-not-index-on-specific-folder.docx",
        content="should-not-index-on-specific-folder",
        folder_path=None,  # root folder
        expected_link_substrings=[
            "_layouts/15/Doc.aspx",
            "file=should-not-index-on-specific-folder.docx",
        ],
    ),
    ExpectedDocument(
        semantic_identifier="other.docx",
        content="other",
        folder_path=None,
        library="Other Library",
        expected_link_substrings=["_layouts/15/Doc.aspx", "file=other.docx"],
    ),
]

EXPECTED_PAGES = [
    ExpectedDocument(
        semantic_identifier="CollabHome",
        content=(
            "# Home\n\nDisplay recent news.\n\n## News\n\nShow recent activities from your site\n\n"
            "## Site activity\n\n## Quick links\n\nLearn about a team site\n\nLearn how to add a page\n\n"
            "Add links to important documents and pages.\n\n## Quick links\n\nDocuments\n\n"
            "Add a document library\n\n## Document library"
        ),
        folder_path=None,
        expected_link_substrings=["SitePages/CollabHome.aspx"],
    ),
    ExpectedDocument(
        semantic_identifier="Home",
        content="# Home",
        folder_path=None,
        expected_link_substrings=["SitePages/Home.aspx"],
    ),
]


def verify_document_metadata(doc: Document) -> None:
    """Verify common metadata that should be present on all documents."""
    assert isinstance(doc.doc_updated_at, datetime)
    assert doc.doc_updated_at.tzinfo == timezone.utc
    assert doc.source == DocumentSource.SHAREPOINT
    assert doc.primary_owners is not None
    assert len(doc.primary_owners) == 1
    owner = doc.primary_owners[0]
    assert owner.display_name is not None
    assert owner.email is not None


def verify_document_content(doc: Document, expected: ExpectedDocument) -> None:
    """Verify a document matches its expected content."""
    assert doc.semantic_identifier == expected.semantic_identifier
    assert len(doc.sections) == 1
    assert doc.sections[0].text is not None
    assert expected.content == doc.sections[0].text

    if expected.expected_link_substrings is not None:
        actual_link = doc.sections[0].link
        assert actual_link is not None, (
            f"Expected section link containing {expected.expected_link_substrings} "
            f"for '{expected.semantic_identifier}', but link was None"
        )
        for substr in expected.expected_link_substrings:
            assert substr in actual_link, (
                f"Section link for '{expected.semantic_identifier}' "
                f"missing expected substring '{substr}', "
                f"actual link: '{actual_link}'"
            )

    verify_document_metadata(doc)


def find_document(documents: list[Document], semantic_identifier: str) -> Document:
    """Find a document by its semantic identifier."""
    matching_docs = [
        d for d in documents if d.semantic_identifier == semantic_identifier
    ]
    assert (
        len(matching_docs) == 1
    ), f"Expected exactly one document with identifier {semantic_identifier}"
    return matching_docs[0]


@pytest.fixture
def mock_store_image() -> MagicMock:
    """Mock store_image_and_create_section to return a predefined ImageSection."""
    mock = MagicMock()
    mock.return_value = (
        ImageSection(image_file_id="mocked-file-id", link="https://example.com/image"),
        "mocked-file-id",
    )
    return mock


@pytest.fixture
def sharepoint_credentials() -> dict[str, str]:
    return {
        "sp_client_id": os.environ["SHAREPOINT_CLIENT_ID"],
        "sp_client_secret": os.environ["SHAREPOINT_CLIENT_SECRET"],
        "sp_directory_id": os.environ["SHAREPOINT_CLIENT_DIRECTORY_ID"],
    }


def test_sharepoint_connector_all_sites__docs_only(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        # Initialize connector with no sites
        connector = SharepointConnector(
            include_site_pages=False, include_site_documents=True
        )

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Not asserting expected sites because that can change in test tenant at any time
        # Finding any docs is good enough to verify that the connector is working
        document_batches = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        )
        assert document_batches, "Should find documents from all sites"


def test_sharepoint_connector_all_sites__pages_only(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        # Initialize connector with no docs
        connector = SharepointConnector(
            include_site_pages=True, include_site_documents=False
        )

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Not asserting expected sites because that can change in test tenant at any time
        # Finding any docs is good enough to verify that the connector is working
        document_batches = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        )
        assert document_batches, "Should find site pages from all sites"


def test_sharepoint_connector_specific_folder(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        # Initialize connector with the test site URL and specific folder
        connector = SharepointConnector(
            sites=[os.environ["SHAREPOINT_SITE"] + "/Shared Documents/test"],
            include_site_pages=False,
            include_site_documents=True,
        )

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Get all documents
        found_documents: list[Document] = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        ).documents

        # Should only find documents in the test folder
        test_folder_docs = [
            doc
            for doc in EXPECTED_DOCUMENTS
            if doc.folder_path and doc.folder_path.startswith("test")
        ]
        assert len(found_documents) == len(
            test_folder_docs
        ), "Should only find documents in test folder"

        # Verify each expected document
        for expected in test_folder_docs:
            doc = find_document(found_documents, expected.semantic_identifier)
            verify_document_content(doc, expected)


def test_sharepoint_connector_root_folder__docs_only(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        # Initialize connector with the base site URL
        connector = SharepointConnector(
            sites=[os.environ["SHAREPOINT_SITE"]],
            include_site_pages=False,
            include_site_documents=True,
        )

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Get all documents
        found_documents: list[Document] = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        ).documents

        assert len(found_documents) == len(
            EXPECTED_DOCUMENTS
        ), "Should find all documents in main library"

        # Verify each expected document
        for expected in EXPECTED_DOCUMENTS:
            doc = find_document(found_documents, expected.semantic_identifier)
            verify_document_content(doc, expected)


def test_sharepoint_connector_other_library(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        # Initialize connector with the other library
        connector = SharepointConnector(
            sites=[
                os.environ["SHAREPOINT_SITE"] + "/Other Library",
            ],
            include_site_pages=False,
            include_site_documents=True,
        )

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Get all documents
        found_documents: list[Document] = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        ).documents
        expected_documents: list[ExpectedDocument] = [
            doc for doc in EXPECTED_DOCUMENTS if doc.library == "Other Library"
        ]

        # Should find all documents in `Other Library`
        assert len(found_documents) == len(
            expected_documents
        ), "Should find all documents in `Other Library`"

        # Verify each expected document
        for expected in expected_documents:
            doc = find_document(found_documents, expected.semantic_identifier)
            verify_document_content(doc, expected)


def test_sharepoint_connector_poll(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        # Initialize connector with the base site URL
        connector = SharepointConnector(sites=[os.environ["SHAREPOINT_SITE"]])

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Set time window to only capture test1.docx (modified at 2025-01-28 20:51:42+00:00)
        start = datetime(
            2025, 1, 28, 20, 51, 30, tzinfo=timezone.utc
        )  # 12 seconds before
        end = datetime(2025, 1, 28, 20, 51, 50, tzinfo=timezone.utc)  # 8 seconds after

        # Get documents within the time window
        found_documents: list[Document] = load_all_from_connector(
            connector=connector,
            start=start.timestamp(),
            end=end.timestamp(),
        ).documents

        # Should only find test1.docx
        assert (
            len(found_documents) == 1
        ), "Should only find one document in the time window"
        doc = found_documents[0]
        assert doc.semantic_identifier == "test1.docx"
        verify_document_content(
            doc,
            next(
                d for d in EXPECTED_DOCUMENTS if d.semantic_identifier == "test1.docx"
            ),
        )


def test_sharepoint_connector_pages(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        connector = SharepointConnector(
            sites=[os.environ["SHAREPOINT_SITE"]],
            include_site_pages=True,
            include_site_documents=False,
        )

        connector.load_credentials(sharepoint_credentials)

        found_documents = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        ).documents

        assert len(found_documents) == len(
            EXPECTED_PAGES
        ), "Should find all pages in test site"

        for expected in EXPECTED_PAGES:
            doc = find_document(found_documents, expected.semantic_identifier)
            verify_document_content(doc, expected)


def verify_hierarchy_nodes(
    hierarchy_nodes: list[HierarchyNode],
    documents: list[Document],
    expected_site_url: str,
) -> None:
    """Verify hierarchy nodes have correct structure and relationships."""
    # Build a set of all raw_node_ids for parent validation
    all_node_ids = {node.raw_node_id for node in hierarchy_nodes}

    # Track nodes by type
    site_nodes = [n for n in hierarchy_nodes if n.node_type == HierarchyNodeType.SITE]
    drive_nodes = [n for n in hierarchy_nodes if n.node_type == HierarchyNodeType.DRIVE]
    folder_nodes = [
        n for n in hierarchy_nodes if n.node_type == HierarchyNodeType.FOLDER
    ]

    # Verify we have at least one site node
    assert len(site_nodes) >= 1, "Should have at least one SITE hierarchy node"
    assert len(drive_nodes) >= 1, "Should have at least one DRIVE hierarchy node"
    assert len(folder_nodes) >= 1, "Should have at least one FOLDER hierarchy node"

    # Verify expected site is in hierarchy
    site_node_ids = {n.raw_node_id for n in site_nodes}
    assert expected_site_url in site_node_ids, (
        f"Expected site {expected_site_url} not found in hierarchy nodes. "
        f"Found sites: {site_node_ids}"
    )

    # Verify no duplicate raw_node_ids
    assert len(all_node_ids) == len(
        hierarchy_nodes
    ), "Should not have duplicate hierarchy nodes"

    # Verify all hierarchy nodes have required fields
    for node in hierarchy_nodes:
        assert node.raw_node_id, "All nodes should have raw_node_id"
        assert node.display_name, "All nodes should have display_name"
        assert node.link, "All nodes should have link"
        assert node.node_type in [
            HierarchyNodeType.SITE,
            HierarchyNodeType.DRIVE,
            HierarchyNodeType.FOLDER,
        ], f"Unexpected node type: {node.node_type}"

    # Verify parent relationships
    for node in hierarchy_nodes:
        if node.node_type == HierarchyNodeType.SITE:
            # Sites should have no parent (direct child of SOURCE)
            assert node.raw_parent_id is None, "SITE nodes should have no parent"
        elif node.node_type == HierarchyNodeType.DRIVE:
            # Drives should have a site as parent
            assert node.raw_parent_id is not None, "DRIVE nodes should have a parent"
            assert (
                node.raw_parent_id in site_node_ids
            ), f"DRIVE parent {node.raw_parent_id} should be a SITE node"
        elif node.node_type == HierarchyNodeType.FOLDER:
            # Folders should have either a drive or another folder as parent
            assert node.raw_parent_id is not None, "FOLDER nodes should have a parent"
            assert (
                node.raw_parent_id in all_node_ids
            ), f"FOLDER parent {node.raw_parent_id} should exist in hierarchy"

    # Verify documents have parent_hierarchy_raw_node_id set
    for doc in documents:
        if doc.parent_hierarchy_raw_node_id:
            assert doc.parent_hierarchy_raw_node_id in all_node_ids, (
                f"Document {doc.semantic_identifier} parent "
                f"{doc.parent_hierarchy_raw_node_id} should exist in hierarchy"
            )


def test_sharepoint_connector_hierarchy_nodes(
    mock_get_unstructured_api_key: MagicMock,  # noqa: ARG001
    mock_store_image: MagicMock,
    sharepoint_credentials: dict[str, str],
) -> None:
    """Test that the SharePoint connector yields proper hierarchy nodes."""
    with patch(
        "onyx.connectors.sharepoint.connector.store_image_and_create_section",
        mock_store_image,
    ):
        site_url = os.environ["SHAREPOINT_SITE"]

        # Initialize connector with the test site
        connector = SharepointConnector(
            sites=[site_url],
            include_site_pages=True,
            include_site_documents=True,
        )

        # Load credentials
        connector.load_credentials(sharepoint_credentials)

        # Get all documents and hierarchy nodes
        result = load_all_from_connector(
            connector=connector,
            start=0,
            end=time.time(),
        )

        found_documents = result.documents
        hierarchy_nodes = result.hierarchy_nodes

        # Should have hierarchy nodes
        assert len(hierarchy_nodes) > 0, "Should have hierarchy nodes"

        # Verify hierarchy structure
        verify_hierarchy_nodes(hierarchy_nodes, found_documents, site_url)

        # Verify we have the expected node types
        node_types = {n.node_type for n in hierarchy_nodes}
        assert HierarchyNodeType.SITE in node_types, "Should have SITE nodes"
        assert HierarchyNodeType.DRIVE in node_types, "Should have DRIVE nodes"

        # Should have folder nodes if documents are in folders
        docs_in_folders = [d for d in EXPECTED_DOCUMENTS if d.folder_path]
        if docs_in_folders:
            assert (
                HierarchyNodeType.FOLDER in node_types
            ), "Should have FOLDER nodes since documents are in folders"

        # Verify all documents have parent_hierarchy_raw_node_id set
        for doc in found_documents:
            assert doc.parent_hierarchy_raw_node_id is not None, (
                f"Document {doc.semantic_identifier} should have "
                "parent_hierarchy_raw_node_id set"
            )
